{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T09:02:31.467563Z",
     "start_time": "2023-06-25T09:02:27.430037Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fariy/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/fariy/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torchvision/image.so, 6): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: /Users/fariy/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torchvision/image.so\n",
      "  Reason: Incompatible library version: image.so requires version 15.0.0 or later, but libjpeg.9.dylib provides version 12.0.0\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "class MultiLabelCNN(nn.Module):\n",
    "    def __init__(self, num_labels, size):\n",
    "        super(MultiLabelCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * (size[0]//8) * (size[1] // 8), 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        #分类\n",
    "        self.sex = nn.Linear(256, 2)\n",
    "        self.nation = nn.Linear(256, 53)\n",
    "        self.right_left = nn.Linear(256, 2)\n",
    "        self.who = nn.Linear(256,num_labels)\n",
    "        #回归\n",
    "        self.age = nn.Linear(256, 1)\n",
    "        self.high = nn.Linear(256, 1)\n",
    "        self.weight = nn.Linear(256, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        #print(f'x:{x,x.shape},sex:{self.sex(x),self.sex(x).shape}')\n",
    "        sex = torch.softmax(self.sex(x), dim=1) \n",
    "        nation = torch.softmax(self.nation(x), dim=1)\n",
    "        right_left = torch.softmax(self.right_left(x), dim=1)\n",
    "        who = torch.softmax(self.who(x), dim=1)\n",
    "        #回归\n",
    "        age = self.age(x)\n",
    "        high = self.high(x)\n",
    "        weight = self.weight(x)\n",
    "        return sex, age,high, weight, nation, right_left, who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T09:02:44.948937Z",
     "start_time": "2023-06-25T09:02:44.933139Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "# 加载模型\n",
    "def load_model(model_class,size,numble_class, path='model.pth'):\n",
    "    model = model_class(numble_class,size)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# 预测函数\n",
    "def predict(image_path, model, size=(96, 160)):\n",
    "    # 图片预处理\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    img_tensor = preprocess(img)\n",
    "    \n",
    "    # 添加batch维度并在GPU上运行（如果可用）\n",
    "    img_tensor.unsqueeze_(0)\n",
    "    img_tensor = img_tensor.to(device=device)\n",
    "    \n",
    "    # 进行预测并返回结果\n",
    "    with torch.no_grad():\n",
    "        output_tuple = model(img_tensor)\n",
    "        results = []\n",
    "        for tensor in output_tuple:\n",
    "            if tensor.numel() == 1:\n",
    "                results.append(tensor.item())\n",
    "            else:\n",
    "                results.append(tensor.cpu().numpy())\n",
    "                \n",
    "        return tuple(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T09:02:49.096048Z",
     "start_time": "2023-06-25T09:02:49.084437Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_prob_index(tensor,dict):\n",
    "        # 转换为NumPy数组\n",
    "    prob_array = np.array(tensor)\n",
    "\n",
    "    # 找到最大值的索引\n",
    "    max_index = np.argmax(prob_array)\n",
    "    result = dict[max_index]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T09:02:54.041959Z",
     "start_time": "2023-06-25T09:02:54.034517Z"
    }
   },
   "outputs": [],
   "source": [
    "sex_dict = {0:'男', 1:'女'}\n",
    "left_right = {0:'右利手', 1:'左利手'}\n",
    "nation_dict = {0: '汉族', 1: '蒙古族', 2: '回族', 3: '藏族', 4: '维吾尔族', 5: '苗族', 6: '彝族', 7: '壮族', 8: '布依族', 9: '朝鲜族', 10: '满族', 11: '侗族', 12: '瑶族', 13: '白族', 14: '土家族', 15: '哈尼族', 16: '哈萨克族', 17: '傣族', 18: '黎族', 19: '傈僳族', 20: '佤族', 21: '畲族', 22: '高山族', 23: '拉祜族', 24: '水族', 25: '东乡族', 26: '纳西族', 27: '景颇族', 28: '柯尔克孜族', 29: '土族', 30: '达斡尔族', 31: '仫佬族', 32: '羌族', 33: '布朗族', 34: '撒拉族', 35: '毛难族', 36: '仡佬族', 37: '锡伯族', 38: '阿昌族', 39: '普米族', 40: '塔吉克族', 41: '怒族', 42: '乌孜别克族', 43: '俄罗斯族', 44: '鄂温克族', 45: '崩龙族', 46: '保安族', 47: '裕固族', 48: '京族', 49: '塔塔尔族', 50: '独龙族', 51: '鄂伦春族', 52: '赫哲族', 53: '门巴族', 54: '珞巴族', 55: '基诺族'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T09:07:25.607567Z",
     "start_time": "2023-06-25T09:07:25.041157Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/cnn_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/zx/vfp8n4ds5glg6634szsl8q2h0000gn/T/ipykernel_12422/356683455.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mimage_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"数据集+信息表+说明/身份识别任务数据集/身份识别任务数据集/训练集/00024/2023-03-20-1.jpg\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mMultiLabelCNN\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnum_labels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'model/cnn_model.pth'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;31m#print(result)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/zx/vfp8n4ds5glg6634szsl8q2h0000gn/T/ipykernel_12422/1746775515.py\u001B[0m in \u001B[0;36mload_model\u001B[0;34m(model_class, size, numble_class, path)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mload_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_class\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mnumble_class\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'model.pth'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_class\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnumble_class\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0msize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[1;32m    769\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    770\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 771\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    772\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    773\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    269\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 270\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    271\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    272\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    250\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 251\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    252\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    253\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'model/cnn_model.pth'"
     ]
    }
   ],
   "source": [
    "\n",
    "num_labels = 31  # 身高，体重，年龄，性别, 民族, 左右利手\n",
    "size = [96,160]\n",
    "image_path = \"数据集+信息表+说明/身份识别任务数据集/身份识别任务数据集/训练集/00024/2023-03-20-1.jpg\"\n",
    "\n",
    "model = load_model(MultiLabelCNN,size,num_labels, 'model/cnn_model.pth')\n",
    "result = predict(image_path, model.to(device))\n",
    "#print(result)\n",
    "\n",
    "#print(f'年龄为：{sex_dict[torch.max(result[0])]} 岁')\n",
    "print(f'年龄为：{result[1]} 岁')\n",
    "print(f'身高为：{result[2]} cm')\n",
    "print(f'体重为：{result[3]} kg')\n",
    "\n",
    "\n",
    "print(f'性别为：{max_prob_index(result[0],dict=sex_dict)} 性')\n",
    "print(f'民族为：{max_prob_index(result[4],dict=nation_dict)}')\n",
    "print(f'左右利手为：{max_prob_index(result[5],dict=left_right)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "女\n"
     ]
    }
   ],
   "source": [
    "print(max_prob_index(result[0],dict=sex_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汉族\n"
     ]
    }
   ],
   "source": [
    "print(max_prob_index(result[4],dict=nation_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '汉族', 1: '蒙古族', 2: '回族', 3: '藏族', 4: '维吾尔族', 5: '苗族', 6: '彝族', 7: '壮族', 8: '布依族', 9: '朝鲜族', 10: '满族', 11: '侗族', 12: '瑶族', 13: '白族', 14: '土家族', 15: '哈尼族', 16: '哈萨克族', 17: '傣族', 18: '黎族', 19: '傈僳族', 20: '佤族', 21: '畲族', 22: '高山族', 23: '拉祜族', 24: '水族', 25: '东乡族', 26: '纳西族', 27: '景颇族', 28: '柯尔克孜族', 29: '土族', 30: '达斡尔族', 31: '仫佬族', 32: '羌族', 33: '布朗族', 34: '撒拉族', 35: '毛难族', 36: '仡佬族', 37: '锡伯族', 38: '阿昌族', 39: '普米族', 40: '塔吉克族', 41: '怒族', 42: '乌孜别克族', 43: '俄罗斯族', 44: '鄂温克族', 45: '崩龙族', 46: '保安族', 47: '裕固族', 48: '京族', 49: '塔塔尔族', 50: '独龙族', 51: '鄂伦春族', 52: '赫哲族', 53: '门巴族', 54: '珞巴族', 55: '基诺族'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_string = '''\n",
    "{\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"id\": \"01\",\n",
    "      \"name\": \"汉族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"02\",\n",
    "      \"name\": \"蒙古族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"03\",\n",
    "      \"name\": \"回族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"04\",\n",
    "      \"name\": \"藏族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"05\",\n",
    "      \"name\": \"维吾尔族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"06\",\n",
    "      \"name\": \"苗族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"07\",\n",
    "      \"name\": \"彝族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"08\",\n",
    "      \"name\": \"壮族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"09\",\n",
    "      \"name\": \"布依族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"10\",\n",
    "      \"name\": \"朝鲜族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"11\",\n",
    "      \"name\": \"满族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"12\",\n",
    "      \"name\": \"侗族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"13\",\n",
    "      \"name\": \"瑶族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"14\",\n",
    "      \"name\": \"白族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"15\",\n",
    "      \"name\": \"土家族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"16\",\n",
    "      \"name\": \"哈尼族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"17\",\n",
    "      \"name\": \"哈萨克族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"18\",\n",
    "      \"name\": \"傣族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"19\",\n",
    "      \"name\": \"黎族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"20\",\n",
    "      \"name\": \"傈僳族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"21\",\n",
    "      \"name\": \"佤族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"22\",\n",
    "      \"name\": \"畲族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"23\",\n",
    "      \"name\": \"高山族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"24\",\n",
    "      \"name\": \"拉祜族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"25\",\n",
    "      \"name\": \"水族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"26\",\n",
    "      \"name\": \"东乡族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"27\",\n",
    "      \"name\": \"纳西族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"28\",\n",
    "      \"name\": \"景颇族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"29\",\n",
    "      \"name\": \"柯尔克孜族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"30\",\n",
    "      \"name\": \"土族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"31\",\n",
    "      \"name\": \"达斡尔族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"32\",\n",
    "      \"name\": \"仫佬族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"33\",\n",
    "      \"name\": \"羌族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"34\",\n",
    "      \"name\": \"布朗族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"35\",\n",
    "      \"name\": \"撒拉族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"36\",\n",
    "      \"name\": \"毛难族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"37\",\n",
    "      \"name\": \"仡佬族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"38\",\n",
    "      \"name\": \"锡伯族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"39\",\n",
    "      \"name\": \"阿昌族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"40\",\n",
    "      \"name\": \"普米族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"41\",\n",
    "      \"name\": \"塔吉克族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"42\",\n",
    "      \"name\": \"怒族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"43\",\n",
    "      \"name\": \"乌孜别克族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"44\",\n",
    "      \"name\": \"俄罗斯族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"45\",\n",
    "      \"name\": \"鄂温克族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"46\",\n",
    "      \"name\": \"崩龙族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"47\",\n",
    "      \"name\": \"保安族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"48\",\n",
    "      \"name\": \"裕固族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"49\",\n",
    "      \"name\": \"京族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"50\",\n",
    "      \"name\": \"塔塔尔族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"51\",\n",
    "      \"name\": \"独龙族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"52\",\n",
    "      \"name\": \"鄂伦春族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"53\",\n",
    "      \"name\": \"赫哲族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"54\",\n",
    "      \"name\": \"门巴族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"55\",\n",
    "      \"name\": \"珞巴族\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"56\",\n",
    "      \"name\": \"基诺族\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "# 将JSON字符串转换为Python字典\n",
    "json_data = json.loads(json_string)\n",
    "\n",
    "# 提取\"data\"列表\n",
    "data_list = json_data[\"data\"]\n",
    "\n",
    "# 创建一个新的字典，其中id作为键，name作为值\n",
    "result_dict = {}\n",
    "for item in data_list:\n",
    "    result_dict[int(item[\"id\"])-1] = item[\"name\"]\n",
    "\n",
    "print(result_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mBART",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
